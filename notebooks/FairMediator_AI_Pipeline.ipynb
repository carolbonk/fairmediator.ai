{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lfKLP-7Jff44"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rONHMaV7jWal"
   },
   "source": "# FairMediator AI Pipeline - Development Notebook\n\n## Project Overview\nAI-powered mediator platform with:\n- **Affiliation Detection** - Identify conflicts of interest\n- **Ideology Classification** - Detect political leanings\n- **Entity Extraction** - Extract organizations, people, locations\n- **Web Scraping** - Collect mediator profiles\n\n## Tech Stack (All FREE)\n- HuggingFace Transformers\n- **Mistral-7B-Instruct** - Advanced reasoning (NEW)\n- **DeBERTa-v3** - Better zero-shot classification (38% faster than BART)\n- **Political Leaning Model** - Specialized ideology detection (+12% accuracy)\n- BeautifulSoup + aiohttp\n- Zero-shot classification\n- Named Entity Recognition (NER)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jKUcgaXtjjEj"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u8V3cjTSjka0"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eFmoVzV6jrIo",
    "outputId": "0c0d52ef-6e88-482f-b082-6903319e9392"
   },
   "outputs": [],
   "source": "# Install required packages\n!pip install -q transformers datasets torch accelerate bitsandbytes\n!pip install -q beautifulsoup4 aiohttp requests\n!pip install -q scikit-learn pandas numpy matplotlib seaborn\n!pip install -q python-dotenv\n\nprint(\"âœ… All packages installed!\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "64TqYjhoj9NE",
    "outputId": "1cb6ed12-9790-410e-882a-221a082fb248"
   },
   "outputs": [],
   "source": [
    "# Core imports\n",
    "import os\n",
    "import re\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "# Data processing\n",
    "import pandas as pd\n",
    "\n",
    "# ML/NLP\n",
    "from transformers import pipeline\n",
    "\n",
    "# Web scraping\n",
    "import aiohttp\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set your HuggingFace API key (get free at\n",
    "# https://huggingface.co/settings/tokens)\n",
    "os.environ['HUGGINGFACE_API_KEY'] = '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'\n",
    "# Replace with your key\n",
    "\n",
    "print(\"âœ… Imports complete!\")\n",
    "print(f\"ğŸ”‘ HuggingFace API: {'Configured' if os.environ.get('HUGGINGFACE_API_KEY') else 'Not set'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W6uymzngkOek",
    "outputId": "9fafcd8c-4af1-4186-892b-98ee57e4ec97"
   },
   "outputs": [],
   "source": "# Load models (this may take a minute on first run)\nprint(\"Loading improved models... â³\")\n\n# 1. Sentiment Analysis (Upgraded to RoBERTa)\nsentiment_classifier = pipeline(\n    \"sentiment-analysis\",\n    model=\"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n)\nprint(\"âœ… Sentiment classifier loaded (RoBERTa - better on reviews)\")\n\n# 2. Named Entity Recognition (Upgraded to BERT-large)\nner_pipeline = pipeline(\n    \"ner\",\n    model=\"dslim/bert-large-NER\",\n    aggregation_strategy=\"simple\"\n)\nprint(\"âœ… NER model loaded (BERT-large - +4.4% F1 score)\")\n\n# 3. Zero-Shot Classification (Upgraded to DeBERTa-v3)\nzero_shot_classifier = pipeline(\n    \"zero-shot-classification\",\n    model=\"MoritzLaurer/deberta-v3-base-zeroshot-v2.0\"\n)\nprint(\"âœ… Zero-shot classifier loaded (DeBERTa-v3 - 38% faster than BART)\")\n\n# 4. Political Ideology Classifier (NEW - Specialized model)\npolitical_classifier = pipeline(\n    \"text-classification\",\n    model=\"matous-volf/political-leaning-politics\"\n)\nprint(\"âœ… Political ideology classifier loaded (Specialized - trained on 12 datasets)\")\n\n# 5. Mistral-7B for complex reasoning (optional - uncomment to use)\n# NOTE: Requires more memory. Use HuggingFace Inference API for free tier instead.\ntry:\n    mistral_generator = pipeline(\n        \"text-generation\",\n        model=\"mistralai/Mistral-7B-Instruct-v0.3\",\n        device_map=\"auto\",\n        model_kwargs={\"load_in_4bit\": True}  # 4-bit quantization for efficiency\n    )\n    print(\"âœ… Mistral-7B loaded (4-bit quantized for complex reasoning)\")\n    MISTRAL_AVAILABLE = True\nexcept Exception as e:\n    print(\"âš ï¸ Mistral-7B not loaded (use HF Inference API instead)\")\n    print(f\"   Error: {str(e)[:100]}\")\n    MISTRAL_AVAILABLE = False\n\nprint(\"\\nğŸ‰ All models ready!\")"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mghBixRBmTyz",
    "outputId": "dc559a53-fd9e-4d76-f2a9-ba1fac30a8c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Sentiment Analysis Results ===\n",
      "\n",
      "ğŸ˜Š POSITIVE (99.9%)\n",
      "   \"The mediator handled our case professionally and f...\"\n",
      "\n",
      "ğŸ˜ NEGATIVE (100.0%)\n",
      "   \"Terrible experience, completely biased towards the...\"\n",
      "\n",
      "ğŸ˜Š POSITIVE (99.3%)\n",
      "   \"Average service, nothing special but got the job d...\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test sentiment analysis on mediator reviews\n",
    "test_reviews = [\n",
    "    \"The mediator handled our case professionally and fairly.\",\n",
    "    \"Terrible experience, completely biased towards the corporation.\",\n",
    "    \"Average service, nothing special but got the job done.\"\n",
    "]\n",
    "\n",
    "print(\"=== Sentiment Analysis Results ===\\n\")\n",
    "for text in test_reviews:\n",
    "    result = sentiment_classifier(text)[0]\n",
    "    emoji = \"ğŸ˜Š\" if result['label'] == 'POSITIVE' else \"ğŸ˜\"\n",
    "    print(f\"{emoji} {result['label']} ({result['score']:.1%})\")\n",
    "    print(f\"   \\\"{text[:50]}...\\\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zUkr6BvsmgzV",
    "outputId": "41fe516a-050b-41b2-bb74-7d4935284362"
   },
   "outputs": [],
   "source": [
    "# Test NER on a mediator bio\n",
    "test_bio = \"\"\"\n",
    "John Buscemi is a senior partner at Morrison & Foerster LLP in San Francisco.\n",
    "He previously worked at the ACLU and served on the board of the Heritage Foundation.\n",
    "He graduated from Harvard Law School and is admitted to the California State Bar.\n",
    "\"\"\"\n",
    "\n",
    "print(\"=== Named Entity Recognition Results ===\\n\")\n",
    "entities = ner_pipeline(test_bio)\n",
    "\n",
    "# Group by entity type\n",
    "entity_groups = {}\n",
    "for ent in entities:\n",
    "    ent_type = ent['entity_group']\n",
    "    if ent_type not in entity_groups:\n",
    "        entity_groups[ent_type] = []\n",
    "    entity_groups[ent_type].append(ent['word'])\n",
    "\n",
    "for ent_type, words in entity_groups.items():\n",
    "    unique_words = list(set(words))\n",
    "    print(f\"ğŸ“Œ {ent_type}: {', '.join(unique_words)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jiXopdQpm36d",
    "outputId": "59ae39d3-2da0-454f-b092-bf47d97206ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Zero-Shot Ideology Classification ===\n",
      "\n",
      "liberal/progressive       â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 98.9%\n",
      "neutral/centrist           0.8%\n",
      "conservative/traditional   0.3%\n"
     ]
    }
   ],
   "source": [
    "# Test ideology detection with zero-shot\n",
    "ideology_text = \"\"\"\n",
    "The mediator has been involved in progressive causes,\n",
    "supporting worker rights\n",
    "and environmental regulations. They've donated to\n",
    "Democratic candidates.\n",
    "\"\"\"\n",
    "\n",
    "candidate_labels = [\"liberal/progressive\",\n",
    "\"conservative/traditional\", \"neutral/centrist\"]\n",
    "\n",
    "print(\"=== Zero-Shot Ideology Classification ===\\n\")\n",
    "result = zero_shot_classifier(ideology_text,\n",
    "candidate_labels)\n",
    "\n",
    "for label, score in zip(result['labels'],\n",
    "result['scores']):\n",
    "    bar = \"â–ˆ\" * int(score * 20)\n",
    "    print(f\"{label:25} {bar} {score:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LRfi-Upjo9zm"
   },
   "source": [
    "## Step 3: Affiliation Detection Pipeline\n",
    "\n",
    "  Detect potential conflicts of interest between\n",
    "  mediators and parties.\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MTo0IvyXo3zX",
    "outputId": "5bb1aabd-9df4-4896-f765-ce4340444ae9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Affiliation Detection Tests ===\n",
      "\n",
      "ğŸš¨ HIGH RISK\n",
      "   Party: Goldman Sachs\n",
      "   Bio: Former partner at Goldman Sachs legal division\n",
      "   Confidence: 99.9%\n",
      "\n",
      "ğŸš¨ HIGH RISK\n",
      "   Party: Acme Corp\n",
      "   Bio: Independent arbitrator with AAA certification\n",
      "   Confidence: 99.9%\n",
      "\n",
      "ğŸš¨ HIGH RISK\n",
      "   Party: Tech Industries\n",
      "   Bio: Served on board of directors for Tech Industries Inc\n",
      "   Confidence: 99.9%\n",
      "\n",
      "ğŸš¨ HIGH RISK\n",
      "   Party: Smith & Jones LLC\n",
      "   Bio: 20 years experience in family law mediation\n",
      "   Confidence: 99.9%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def detect_affiliation(text: str, party_name: str = None) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Detect potential conflicts of interest using zero-shot classification.\n",
    "    \"\"\"\n",
    "    labels = [\"potential conflict of interest\", \"no conflict of interest\"]\n",
    "\n",
    "    # If party name provided, include it in the analysis\n",
    "    if party_name:\n",
    "        analysis_text = f\"Check if mediator has connection to {party_name}: {text}\"\n",
    "    else:\n",
    "        analysis_text = text\n",
    "\n",
    "    result = zero_shot_classifier(analysis_text, labels)\n",
    "\n",
    "    is_conflict = result['labels'][0] == \"potential conflict of interest\"\n",
    "\n",
    "    return {\n",
    "        'text': text[:100] + '...' if len(text) > 100 else text,\n",
    "        'prediction': result['labels'][0],\n",
    "        'confidence': result['scores'][0],\n",
    "        'is_conflict': is_conflict,\n",
    "        'risk_level': 'HIGH' if is_conflict and result['scores'][0] > 0.7 else \\\n",
    "                      'MEDIUM' if is_conflict else 'LOW'\n",
    "    }\n",
    "\n",
    "# Test affiliation detection\n",
    "print(\"=== Affiliation Detection Tests ===\\n\")\n",
    "\n",
    "test_cases = [\n",
    "    (\"Former partner at Goldman Sachs legal division\", \"Goldman Sachs\"),\n",
    "    (\"Independent arbitrator with AAA certification\", \"Acme Corp\"),\n",
    "    (\"Served on board of directors for Tech Industries Inc\", \"Tech Industries\"),\n",
    "    (\"20 years experience in family law mediation\", \"Smith & Jones LLC\")\n",
    "]\n",
    "\n",
    "for bio, party in test_cases:\n",
    "    result = detect_affiliation(bio, party)\n",
    "\n",
    "    if result['risk_level'] == 'HIGH':\n",
    "        emoji = \"ğŸš¨\"\n",
    "    elif result['risk_level'] == 'MEDIUM':\n",
    "        emoji = \"âš ï¸\"\n",
    "    else:\n",
    "        emoji = \"âœ…\"\n",
    "\n",
    "    print(f\"{emoji} {result['risk_level']} RISK\")\n",
    "    print(f\"   Party: {party}\")\n",
    "    print(f\"   Bio: {bio}\")\n",
    "    print(f\"   Confidence: {result['confidence']:.1%}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ck8yujLMpWvm"
   },
   "source": [
    "## Step 4: Ideology Classification\n",
    "\n",
    "  Detect political leaning based on affiliations,\n",
    "  donations, and statements.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3RoxfsCnpZ8u",
    "outputId": "bc70eca1-847e-4b50-a02f-fa15fccdb475"
   },
   "outputs": [],
   "source": "class ImprovedIdeologyClassifier:\n    \"\"\"Enhanced ideology classifier using specialized political model + keywords.\"\"\"\n\n    def __init__(self):\n        # Keyword indicators (unchanged)\n        self.liberal_keywords = [\n            'progressive', 'equality', 'social justice', 'environmental',\n            'civil rights', 'labor rights', 'ACLU', 'diversity', 'inclusion',\n            'worker protection', 'regulation', 'climate', 'equity'\n        ]\n\n        self.conservative_keywords = [\n            'traditional', 'liberty', 'free market', 'constitutional',\n            'heritage foundation', 'family values', 'federalist',\n            'limited government', 'deregulation', 'individual responsibility'\n        ]\n\n        # Organization affiliations\n        self.liberal_orgs = ['ACLU', 'Sierra Club', 'Planned Parenthood', 'NAACP']\n        self.conservative_orgs = ['Heritage Foundation', 'Federalist Society', 'NRA', 'Cato Institute']\n\n    def keyword_score(self, text: str) -> float:\n        \"\"\"Calculate score based on keywords (-10 to +10).\"\"\"\n        text_lower = text.lower()\n\n        liberal_count = sum(1 for kw in self.liberal_keywords if kw.lower() in text_lower)\n        conservative_count = sum(1 for kw in self.conservative_keywords if kw.lower() in text_lower)\n\n        # Check organizations (weighted higher)\n        liberal_count += sum(2 for org in self.liberal_orgs if org.lower() in text_lower)\n        conservative_count += sum(2 for org in self.conservative_orgs if org.lower() in text_lower)\n\n        total = liberal_count + conservative_count\n        if total == 0:\n            return 0\n\n        return round(((conservative_count - liberal_count) / total) * 10, 2)\n\n    def ml_classify(self, text: str) -> Dict[str, Any]:\n        \"\"\"Use specialized political classifier (NEW - much better accuracy).\"\"\"\n        result = political_classifier(text)[0]\n        \n        # Map to -10 to +10 scale\n        label_to_score = {\n            'left': -8,\n            'center': 0,\n            'right': 8\n        }\n        \n        ml_score = label_to_score.get(result['label'], 0)\n\n        return {\n            'label': result['label'],\n            'ml_score': ml_score,\n            'confidence': result['score']\n        }\n\n    def classify(self, text: str) -> Dict[str, Any]:\n        \"\"\"Combined classification (70% ML, 30% keywords) - improved weighting.\"\"\"\n        keyword_score = self.keyword_score(text)\n        ml_result = self.ml_classify(text)\n\n        # 70% specialized ML model, 30% keyword matching\n        combined_score = 0.7 * ml_result['ml_score'] + 0.3 * keyword_score\n\n        # Determine leaning\n        if combined_score < -3:\n            leaning = 'liberal'\n            color = 'ğŸ”µ'\n        elif combined_score > 3:\n            leaning = 'conservative'\n            color = 'ğŸ”´'\n        else:\n            leaning = 'neutral'\n            color = 'âšª'\n\n        return {\n            'leaning': leaning,\n            'color': color,\n            'combined_score': round(combined_score, 2),\n            'keyword_score': keyword_score,\n            'ml_score': ml_result['ml_score'],\n            'ml_label': ml_result['label'],\n            'confidence': ml_result['confidence']\n        }\n\n# Initialize improved classifier\nideology_classifier = ImprovedIdeologyClassifier()\nprint(\"âœ… ImprovedIdeologyClassifier initialized (using specialized political model)\")"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tKlwZtubprSr",
    "outputId": "f09b3525-3fc8-47ec-c819-3814b792da3c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Ideology Classification Results ===\n",
      "\n",
      "ğŸ”µ Mediator 1: LIBERAL\n",
      "   Combined Score: -9.97 (scale: -10 liberal to +10 conservative)\n",
      "   Confidence: 99.5%\n",
      "   Keyword Score: -10.0\n",
      "   ML Score: -9.95\n",
      "\n",
      "ğŸ”´ Mediator 2: CONSERVATIVE\n",
      "   Combined Score: 9.49 (scale: -10 liberal to +10 conservative)\n",
      "   Confidence: 91.5%\n",
      "   Keyword Score: 10.0\n",
      "   ML Score: 9.15\n",
      "\n",
      "âšª Mediator 3: NEUTRAL\n",
      "   Combined Score: 1.74 (scale: -10 liberal to +10 conservative)\n",
      "   Confidence: 54.4%\n",
      "   Keyword Score: 0\n",
      "   ML Score: 2.9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test with different mediator profiles\n",
    "test_bios = [\n",
    "    \"\"\"Sarah Johnson has been a vocal advocate for worker rights and environmental protection. She serves on the board of the Sierra Club and has donated to progressive causes including the ACLU.\"\"\",\n",
    "    \"\"\"Michael Williams is a member of the Federalist Society and advocates for constitutional originalism and limited government. He has written extensively about free market principles and individual liberty.\"\"\",\n",
    "    \"\"\"Jennifer Chen is a certified mediator with 15 years of experience in commercial disputes. She focuses on finding practical solutions and maintaining strict neutrality between all parties.\"\"\"\n",
    "]\n",
    "\n",
    "print(\"=== Ideology Classification Results ===\\n\")\n",
    "\n",
    "for i, bio in enumerate(test_bios, 1):\n",
    "    result = ideology_classifier.classify(bio)\n",
    "\n",
    "    print(f\"{result['color']} Mediator {i}: {result['leaning'].upper()}\")\n",
    "    print(f\"   Combined Score: {result['combined_score']} (scale: -10 liberal to +10 conservative)\")\n",
    "    print(f\"   Confidence: {result['confidence']:.1%}\")\n",
    "    print(f\"   Keyword Score: {result['keyword_score']}\")\n",
    "    print(f\"   ML Score: {result['ml_score']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m-VhaAESqs6L"
   },
   "source": [
    " ## Step 5: Web Scraping Integration\n",
    "\n",
    "  Collect mediator profiles from legal databases using\n",
    "  BeautifulSoup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0s-EoZB3r3Ih",
    "outputId": "970f32a6-d3c3-4e69-9bf2-b75bba0f89a1"
   },
   "outputs": [],
   "source": [
    "class MediatorScraper:\n",
    "    \"\"\"Scrape mediator profiles from web sources.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36'\n",
    "        }\n",
    "\n",
    "    async def fetch_page(self, url: str) -> str:\n",
    "        \"\"\"Fetch a web page asynchronously.\"\"\"\n",
    "        async with aiohttp.ClientSession() as session:\n",
    "            async with session.get(url, headers=self.headers, timeout=10) as response:\n",
    "                return await response.text()\n",
    "\n",
    "    def extract_text(self, html: str) -> str:\n",
    "        \"\"\"Extract clean text from HTML.\"\"\"\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "        # Remove unwanted elements\n",
    "        for element in soup(['script', 'style', 'nav', 'footer', 'header']):\n",
    "            element.decompose()\n",
    "\n",
    "        return soup.get_text(separator=' ', strip=True)\n",
    "\n",
    "    def extract_entities(self, text: str) -> Dict[str, List[str]]:\n",
    "        \"\"\"Extract organizations, people, locations using NER.\"\"\"\n",
    "        # Limit text for performance\n",
    "        entities = ner_pipeline(text[:3000])\n",
    "\n",
    "        result = {'ORG': [], 'PER': [], 'LOC': []}\n",
    "\n",
    "        for ent in entities:\n",
    "            ent_type = ent['entity_group']\n",
    "            if ent_type in result:\n",
    "                result[ent_type].append(ent['word'])\n",
    "\n",
    "        # Deduplicate\n",
    "        for key in result:\n",
    "            result[key] = list(set(result[key]))\n",
    "\n",
    "        return result\n",
    "\n",
    "    def extract_contact_info(self, text: str) -> Dict[str, str]:\n",
    "        \"\"\"Extract email, phone from text.\"\"\"\n",
    "        patterns = {\n",
    "            'email': r'[\\w.-]+@[\\w.-]+\\.\\w+',\n",
    "            'phone': r'\\(?\\d{3}\\)?[-.\\s]?\\d{3}[-.\\s]?\\d{4}',\n",
    "            'hourly_rate': r'\\$\\d{1,3}(?:,\\d{3})*(?:\\.\\d{2})?(?:/hr|/hour)?'\n",
    "        }\n",
    "\n",
    "        result = {}\n",
    "        for key, pattern in patterns.items():\n",
    "            match = re.search(pattern, text, re.IGNORECASE)\n",
    "            result[key] = match.group() if match else None\n",
    "\n",
    "        return result\n",
    "\n",
    "    async def analyze_url(self, url: str) -> Dict[str, Any]:\n",
    "        \"\"\"Scrape and analyze a URL.\"\"\"\n",
    "        try:\n",
    "            html = await self.fetch_page(url)\n",
    "            text = self.extract_text(html)\n",
    "\n",
    "            return {\n",
    "                'url': url,\n",
    "                'text_length': len(text),\n",
    "                'entities': self.extract_entities(text),\n",
    "                'contact': self.extract_contact_info(text),\n",
    "                'preview': text[:500]\n",
    "            }\n",
    "        except Exception as e:\n",
    "            return {'url': url, 'error': str(e)}\n",
    "\n",
    "# Initialize scraper\n",
    "scraper = MediatorScraper()\n",
    "print(\"âœ… MediatorScraper initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i4FBdm5bskot",
    "outputId": "928913e1-fdc5-4c6c-a412-f342acbdb36c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“ Scraping: https://en.wikipedia.org/wiki/Mediation\n",
      "âœ… Successfully scraped https://en.wikipedia.org/wiki/Mediation\n",
      "   Text length: 151 characters\n",
      "   Entities: {'ORG': [], 'PER': [], 'LOC': []}\n",
      "   Contact Info: {'email': 'bot-traffic@wikimedia.org', 'phone': None, 'hourly_rate': None}\n",
      "   Preview: Please respect our robot policy https://w.wiki/4wJS when crawling us. Contact bot-traffic@wikimedia.org if you need higher volumes. (b74d0e2) (30224bb)...\n"
     ]
    }
   ],
   "source": [
    "# Test scraping a public page\n",
    "async def demo_scrape():\n",
    "    # Using Wikipedia as a safe demo URL\n",
    "    url = \"https://en.wikipedia.org/wiki/Mediation\"\n",
    "    print(f\"\\nğŸ“ Scraping: {url}\")\n",
    "    analysis_result = await scraper.analyze_url(url)\n",
    "\n",
    "    if 'error' in analysis_result:\n",
    "        print(f\"âŒ Error scraping {url}: {analysis_result['error']}\")\n",
    "    else:\n",
    "        print(f\"âœ… Successfully scraped {url}\")\n",
    "        print(f\"   Text length: {analysis_result['text_length']} characters\")\n",
    "        print(f\"   Entities: {analysis_result['entities']}\")\n",
    "        print(f\"   Contact Info: {analysis_result['contact']}\")\n",
    "        print(f\"   Preview: {analysis_result['preview'][:200]}...\")\n",
    "\n",
    "# Run the async scraping demo\n",
    "await demo_scrape()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S0d7cNLBtS3g"
   },
   "source": [
    "## Step 6: Interactive Testing Widgets\n",
    "\n",
    "  Test the AI pipeline with custom inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h6ABlcWptauQ",
    "outputId": "58d542fc-51ba-4da4-e9cb-fcef657117ad"
   },
   "outputs": [],
   "source": [
    "def analyze_mediator_input():\n",
    "    \"\"\"Interactive form for testing the pipeline.\"\"\"\n",
    "\n",
    "    print(\"=\" * 50)\n",
    "    print(\"ğŸ”¬ MEDIATOR ANALYSIS TOOL\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    # Get user input\n",
    "    print(\"\\nEnter mediator bio (or press Enter for demo):\")\n",
    "    bio = input() or \"\"\"\n",
    "Robert Thompson is a partner at Wilson & Associates LLP.\n",
    "He previously\n",
    "served as general counsel for Tech Corp Inc and sits on\n",
    "the board of\n",
    "the American Bar Association. He's a member of the\n",
    "Federalist Society.\n",
    "\"\"\"\n",
    "\n",
    "    print(\"\\nEnter party name to check conflicts (or press Enter to skip):\")\n",
    "    party = input() or \"Tech Corp\"\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"ANALYSIS RESULTS\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    # Run ideology classification\n",
    "    ideology_result = ideology_classifier.classify(bio)\n",
    "    print(f\"\\n{ideology_result['color']} IDEOLOGY: {ideology_result['leaning'].upper()}\")\n",
    "    print(f\"   Score: {ideology_result['combined_score']} (-10 to +10)\")\n",
    "    print(f\"   Confidence: {ideology_result['confidence']:.1%}\")\n",
    "\n",
    "    # Run affiliation detection\n",
    "    affiliation_result = detect_affiliation(bio, party)\n",
    "    risk_emoji = \"ğŸš¨\" if affiliation_result['risk_level'] == 'HIGH' else \"âš ï¸\" if affiliation_result['risk_level'] == 'MEDIUM' else \"âœ…\"\n",
    "    print(f\"\\n{risk_emoji} CONFLICT RISK: {affiliation_result['risk_level']}\")\n",
    "    print(f\"   Party checked: {party}\")\n",
    "    print(f\"   Confidence: {affiliation_result['confidence']:.1%}\")\n",
    "\n",
    "    # Run NER\n",
    "    entities = ner_pipeline(bio)\n",
    "    orgs = list(set([e['word'] for e in entities if e['entity_group'] == 'ORG']))\n",
    "    if orgs:\n",
    "        print(f\"\\nğŸ¢ ORGANIZATIONS FOUND: {', '.join(orgs)}\")\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "\n",
    "# Run the interactive tool\n",
    "analyze_mediator_input()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sSgjpPlkuGqO"
   },
   "source": [
    "## Step 7: Visualization\n",
    "\n",
    "  Create charts to display analysis results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 473
    },
    "id": "RpFadkzWuXZx",
    "outputId": "ac5c3544-d4eb-46b2-a653-acdd427368ba"
   },
   "outputs": [],
   "source": [
    "# Sample data for visualization\n",
    "mediators_data = [\n",
    "    {'name': 'Sarah Johnson', 'ideology': -6.5, 'experience': 15, 'rate': 350},\n",
    "    {'name': 'Michael Williams', 'ideology': 7.2, 'experience': 20, 'rate': 500},\n",
    "    {'name': 'Jennifer Chen', 'ideology': 0.5, 'experience': 12, 'rate': 300},\n",
    "    {'name': 'David Brown', 'ideology': -3.1, 'experience': 8, 'rate': 250},\n",
    "    {'name': 'Lisa Anderson', 'ideology': 4.8, 'experience': 18, 'rate': 450}\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(mediators_data)\n",
    "\n",
    "# Create figure with subplots\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# Plot 1: Ideology Distribution\n",
    "colors = ['blue' if x < -3 else 'red' if x > 3 else 'gray' for x in df['ideology']]\n",
    "axes[0].barh(df['name'], df['ideology'], color=colors)\n",
    "axes[0].axvline(x=0, color='black', linestyle='-', linewidth=0.5)\n",
    "axes[0].axvline(x=-3, color='blue', linestyle='--', linewidth=0.5, alpha=0.5)\n",
    "axes[0].axvline(x=3, color='red', linestyle='--', linewidth=0.5, alpha=0.5)\n",
    "axes[0].set_xlabel('Ideology Score (-10 Liberal to +10 Conservative)')\n",
    "axes[0].set_title('Mediator Ideology Distribution')\n",
    "\n",
    "# Plot 2: Experience vs Rate\n",
    "axes[1].scatter(df['experience'], df['rate'], c=df['ideology'], cmap='coolwarm', s=100)\n",
    "axes[1].set_xlabel('Years Experience')\n",
    "axes[1].set_ylabel('Hourly Rate ($)')\n",
    "axes[1].set_title('Experience vs Rate (color = ideology)')\n",
    "\n",
    "# Plot 3: Rate Distribution\n",
    "axes[2].hist(df['rate'], bins=5, color='steelblue', edgecolor='black')\n",
    "axes[2].set_xlabel('Hourly Rate ($)')\n",
    "axes[2].set_ylabel('Count')\n",
    "axes[2].set_title('Rate Distribution')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nâœ… Visualizations complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4reM2ghqzv8b"
   },
   "source": [
    "## Step 8: Full Pipeline Demo\n",
    "\n",
    "  Complete end-to-end demonstration of the FairMediator AI\n",
    "  pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h2Vy6X5pzzlV",
    "outputId": "48240ad2-fd7a-4e78-c70b-6a91f77e69a4"
   },
   "outputs": [],
   "source": "def full_mediator_analysis(bio: str, parties: List[str] = None, use_mistral: bool = False) -> Dict[str, Any]:\n    \"\"\"\n    Run complete analysis pipeline on a mediator.\n\n    Args:\n        bio: Mediator biography/profile text\n        parties: List of party names to check for conflicts\n        use_mistral: Use Mistral-7B for advanced reasoning (optional)\n\n    Returns:\n        Complete analysis results\n    \"\"\"\n    results = {\n        'input': {\n            'bio_length': len(bio),\n            'parties_checked': parties or []\n        },\n        'ideology': None,\n        'entities': None,\n        'conflicts': [],\n        'sentiment': None,\n        'recommendation': None\n    }\n\n    # 1. Ideology Classification (using improved specialized model)\n    results['ideology'] = ideology_classifier.classify(bio)\n\n    # 2. Entity Extraction (with improved BERT-large)\n    entities = ner_pipeline(bio[:3000])\n    results['entities'] = {\n        'organizations': list(set([e['word'] for e in entities if e['entity_group'] == 'ORG'])),\n        'people': list(set([e['word'] for e in entities if e['entity_group'] == 'PER'])),\n        'locations': list(set([e['word'] for e in entities if e['entity_group'] == 'LOC']))\n    }\n\n    # 3. Conflict Detection (for each party) - using improved DeBERTa-v3\n    if parties:\n        for party in parties:\n            conflict = detect_affiliation(bio, party)\n            conflict['party'] = party\n            results['conflicts'].append(conflict)\n\n    # 4. Overall Sentiment (using improved RoBERTa)\n    sentiment = sentiment_classifier(bio[:500])[0]\n    results['sentiment'] = {\n        'label': sentiment['label'],\n        'score': sentiment['score']\n    }\n\n    # 5. Advanced Mistral-7B Analysis (optional)\n    if use_mistral and MISTRAL_AVAILABLE:\n        prompt = f\"\"\"[INST] Analyze this mediator profile for potential conflicts and political leanings.\n        \nMediator Bio: {bio[:1000]}\nParties to check: {', '.join(parties) if parties else 'None'}\n\nProvide a brief analysis focusing on:\n1. Political ideology (left/center/right) with reasoning\n2. Any potential conflicts of interest\n3. Overall recommendation\n\nBe concise and objective. [/INST]\"\"\"\n        \n        mistral_output = mistral_generator(\n            prompt, \n            max_new_tokens=300,\n            temperature=0.3,\n            do_sample=True\n        )[0]['generated_text']\n        \n        # Extract just the response (after [/INST])\n        if '[/INST]' in mistral_output:\n            mistral_output = mistral_output.split('[/INST]')[-1].strip()\n        \n        results['mistral_analysis'] = mistral_output\n\n    # 6. Generate Recommendation\n    has_high_risk = any(c['risk_level'] == 'HIGH' for c in results['conflicts'])\n    has_medium_risk = any(c['risk_level'] == 'MEDIUM' for c in results['conflicts'])\n\n    if has_high_risk:\n        results['recommendation'] = {\n            'status': 'NOT RECOMMENDED',\n            'reason': 'High conflict risk detected',\n            'emoji': 'ğŸš«'\n        }\n    elif has_medium_risk:\n        results['recommendation'] = {\n            'status': 'REVIEW REQUIRED',\n            'reason': 'Potential conflicts need review',\n            'emoji': 'âš ï¸'\n        }\n    else:\n        results['recommendation'] = {\n            'status': 'RECOMMENDED',\n            'reason': 'No significant conflicts detected',\n            'emoji': 'âœ…'\n        }\n\n    return results\n\nprint(\"âœ… Full pipeline function ready (with optional Mistral-7B support)\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qscs-b9p0JV4"
   },
   "outputs": [],
   "source": "# Demo: Full pipeline analysis with improved models\ndemo_bio = \"\"\"\nPatricia Martinez is a senior mediator at Pacific Dispute Resolution in Los Angeles.\nShe has 18 years of experience specializing in employment and commercial disputes.\nPreviously, she was a partner at Morrison & Foerster LLP and served as in-house\ncounsel for TechStart Inc. She is a member of the American Bar Association and\nhas volunteered with the ACLU on civil rights cases. She holds certifications\nfrom JAMS and the American Arbitration Association. Hourly rate: $400/hr.\nContact: pmartinez@pacificdr.com | (310) 555-1234\n\"\"\"\n\ndemo_parties = [\"TechStart Inc\", \"Morrison & Foerster\", \"Google LLC\"]\n\nprint(\"=\" * 60)\nprint(\"ğŸ” FULL MEDIATOR ANALYSIS (IMPROVED MODELS)\")\nprint(\"=\" * 60)\n\n# Test with standard models\nprint(\"\\nğŸ“Š Running analysis with improved specialized models...\")\nresults = full_mediator_analysis(demo_bio, demo_parties, use_mistral=False)\n\n# Display results\nprint(f\"\\n{results['recommendation']['emoji']} RECOMMENDATION: {results['recommendation']['status']}\")\nprint(f\"   Reason: {results['recommendation']['reason']}\")\n\nprint(f\"\\n{results['ideology']['color']} IDEOLOGY: {results['ideology']['leaning'].upper()}\")\nprint(f\"   ML Model: {results['ideology']['ml_label']} ({results['ideology']['confidence']:.1%} confidence)\")\nprint(f\"   Combined Score: {results['ideology']['combined_score']} (-10 liberal to +10 conservative)\")\nprint(f\"   Keyword Score: {results['ideology']['keyword_score']}\")\nprint(f\"   ML Score: {results['ideology']['ml_score']}\")\n\nprint(f\"\\nğŸ¢ ORGANIZATIONS: {', '.join(results['entities']['organizations'][:5])}\")\nprint(f\"ğŸ“ LOCATIONS: {', '.join(results['entities']['locations'][:3])}\")\n\nprint(\"\\nâš–ï¸ CONFLICT ANALYSIS:\")\nfor conflict in results['conflicts']:\n    risk_emoji = \"ğŸš¨\" if conflict['risk_level'] == 'HIGH' else \"âš ï¸\" if conflict['risk_level'] == 'MEDIUM' else \"âœ…\"\n    print(f\"   {risk_emoji} {conflict['party']}: {conflict['risk_level']} ({conflict['confidence']:.0%})\")\n\nprint(f\"\\nğŸ˜Š SENTIMENT: {results['sentiment']['label']} ({results['sentiment']['score']:.1%})\")\n\n# Optional: Test with Mistral if available\nif MISTRAL_AVAILABLE:\n    print(\"\\n\" + \"=\" * 60)\n    print(\"ğŸ¤– MISTRAL-7B ADVANCED ANALYSIS\")\n    print(\"=\" * 60)\n    results_mistral = full_mediator_analysis(demo_bio, demo_parties, use_mistral=True)\n    print(f\"\\n{results_mistral['mistral_analysis']}\")\nelse:\n    print(\"\\n\" + \"=\" * 60)\n    print(\"ğŸ’¡ TIP: To use Mistral-7B advanced analysis:\")\n    print(\"   - Option 1: Load locally (requires ~4GB RAM with 4-bit quantization)\")\n    print(\"   - Option 2: Use HuggingFace Inference API (free tier: ~300 req/hour)\")\n    print(\"=\" * 60)\n\nprint(\"\\n\" + \"=\" * 60)"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vKkNNhn60OnS"
   },
   "source": [
    "## Step 9: Integration with FairMediator Backend\n",
    "\n",
    "  How to connect this notebook to your production system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6umhVBYC0RxM"
   },
   "outputs": [],
   "source": [
    "# Example: How to call FairMediator backend APIs\n",
    "import requests\n",
    "\n",
    "# Your backend URL (local or deployed)\n",
    "BACKEND_URL = \"http://localhost:5001\"  # Change for production\n",
    "\n",
    "def call_fairmediator_api(endpoint: str, data: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Call FairMediator backend API.\n",
    "\n",
    "    Available endpoints:\n",
    "    - POST /api/chat/enrich-mediator\n",
    "    - POST /api/chat/check-conflicts\n",
    "    - POST /api/chat/analyze-ideology\n",
    "    - GET /api/chat/scraper-health\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = requests.post(\n",
    "            f\"{BACKEND_URL}{endpoint}\",\n",
    "            json=data,\n",
    "            timeout=30\n",
    "        )\n",
    "        return response.json()\n",
    "    except Exception as e:\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "# Example usage (uncomment to test with running backend)\n",
    "# result = call_fairmediator_api(\"/api/chat/enrich-mediator\", {\n",
    "#     \"mediatorName\": \"John Smith\"\n",
    "# })\n",
    "# print(result)\n",
    "\n",
    "print(\"\"\"\n",
    "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "â•‘  BACKEND INTEGRATION GUIDE                                   â•‘\n",
    "â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£\n",
    "â•‘                                                              â•‘\n",
    "â•‘  To use with FairMediator backend:                           â•‘\n",
    "â•‘                                                              â•‘\n",
    "â•‘  1. Start backend: cd backend && npm run dev                 â•‘\n",
    "â•‘                                                              â•‘\n",
    "â•‘  2. Start Python scraper:                                    â•‘\n",
    "â•‘     cd backend/src/services/scraper/python                   â•‘\n",
    "â•‘     python scraper_service.py                                â•‘\n",
    "â•‘                                                              â•‘\n",
    "â•‘  3. API Endpoints:                                           â•‘\n",
    "â•‘     POST /api/chat/enrich-mediator                           â•‘\n",
    "â•‘     POST /api/chat/check-conflicts                           â•‘\n",
    "â•‘     POST /api/chat/analyze-ideology                          â•‘\n",
    "â•‘     POST /api/chat/bulk-scrape                               â•‘\n",
    "â•‘                                                              â•‘\n",
    "â•‘  4. Frontend connects automatically via React components     â•‘\n",
    "â•‘                                                              â•‘\n",
    "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GQWr_Dyh0eYw"
   },
   "source": [
    "Markdown - Summary & Next Steps\n",
    "\n",
    "  ---\n",
    "  ## Summary & Next Steps\n",
    "\n",
    "  ### âœ… What We Built\n",
    "  1. **Text Classification** - Sentiment analysis on reviews\n",
    "  2. **Named Entity Recognition** - Extract organizations, people,\n",
    "   locations\n",
    "  3. **Zero-Shot Classification** - Flexible ideology/affiliation\n",
    "  detection\n",
    "  4. **Affiliation Detector** - Identify conflicts of interest\n",
    "  5. **Ideology Classifier** - Political leaning detection\n",
    "  (keyword + ML)\n",
    "  6. **Web Scraper** - Collect mediator profiles\n",
    "  7. **Full Pipeline** - End-to-end analysis function\n",
    "\n",
    "  ### ğŸš€ Next Steps\n",
    "\n",
    "  **Data Collection:**\n",
    "  - Scrape real mediator profiles from Martindale, Avvo, Justia\n",
    "  - Build labeled dataset for fine-tuning (1000+ samples)\n",
    "  - Add FEC donation data integration\n",
    "\n",
    "  **Model Improvements:**\n",
    "  - Fine-tune DistilBERT on legal domain text\n",
    "  - Add custom NER for legal entities (case types, jurisdictions)\n",
    "  - Implement confidence calibration\n",
    "\n",
    "  **Production Deployment:**\n",
    "  - Export models to HuggingFace Hub\n",
    "  - Set up model versioning\n",
    "  - Add A/B testing for model comparisons\n",
    "\n",
    "  **Frontend Integration:**\n",
    "  - Connect visualization charts to React dashboard\n",
    "  - Add real-time analysis in chat panel\n",
    "  - Create mediator comparison views\n",
    "\n",
    "  ### ğŸ“š Resources\n",
    "  - HuggingFace: https://huggingface.co/CarolBonk\n",
    "  - Transformers Docs: https://huggingface.co/docs/transformers\n",
    "  - FairMediator Repo: Your GitHub repository\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u1KALfUa0jMA"
   },
   "source": [
    "Code - Final Summary\n",
    "\n",
    "  print(\"\"\"\n",
    "  â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "  â•‘     ğŸ‰ FAIRMEDIATOR AI PIPELINE COMPLETE! ğŸ‰                â•‘\n",
    "  â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£\n",
    "  â•‘                                                              â•‘\n",
    "  â•‘  âœ… Text Classification (Sentiment)                          â•‘\n",
    "  â•‘  âœ… Named Entity Recognition (NER)                           â•‘\n",
    "  â•‘  âœ… Zero-Shot Classification                                 â•‘\n",
    "  â•‘  âœ… Affiliation Detection Pipeline                           â•‘\n",
    "  â•‘  âœ… Ideology Classification (Keywords + ML)                  â•‘\n",
    "  â•‘  âœ… Web Scraping Integration                                 â•‘\n",
    "  â•‘  âœ… Interactive Testing Tools                                â•‘\n",
    "  â•‘  âœ… Visualization Charts                                     â•‘\n",
    "  â•‘  âœ… Full Pipeline Demo                                       â•‘\n",
    "  â•‘  âœ… Backend Integration Guide                                â•‘\n",
    "  â•‘                                                              â•‘\n",
    "  â•‘  All using FREE tier:                                        â•‘\n",
    "  â•‘  â€¢ HuggingFace Transformers                                  â•‘\n",
    "  â•‘  â€¢ Google Colab                                              â•‘\n",
    "  â•‘  â€¢ Open-source libraries                                     â•‘             â•‘                                                              â•‘\n",
    "  â•‘                                                              â•‘\n",
    "  â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "  \"\"\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}